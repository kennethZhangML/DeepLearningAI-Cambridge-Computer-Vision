{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os \r\n",
    "import numpy as np \r\n",
    "import pandas as pd \r\n",
    "\r\n",
    "import tensorflow as tf \r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import regularizers, initializers, optimizers\r\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "base_dir = os.path.join(\"C:/Users/kzhan/Desktop/archive\")\r\n",
    "training_dir = os.path.join(base_dir + \"/Training\")\r\n",
    "testing_dir = os.path.join(base_dir + \"/Testing\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "batch_size, img_height, img_width = 64, 180, 180\r\n",
    "\r\n",
    "#Load images from a directory to a tf.data.Dataset\r\n",
    "training_data = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "    directory = training_dir,\r\n",
    "    validation_split = 0.2,\r\n",
    "    subset = \"training\",\r\n",
    "    seed = 123,\r\n",
    "    image_size = (img_height, img_width),\r\n",
    "    batch_size = batch_size)\r\n",
    "\r\n",
    "#Load images from a directory to a tf.data.Dataset\r\n",
    "validation_data = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "    directory = training_dir,\r\n",
    "    validation_split = 0.2,\r\n",
    "    subset = \"validation\",\r\n",
    "    seed = 123,\r\n",
    "    image_size = (img_height, img_width),\r\n",
    "    batch_size = batch_size\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2870 files belonging to 4 classes.\n",
      "Using 2296 files for training.\n",
      "Found 2870 files belonging to 4 classes.\n",
      "Using 574 files for validation.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def get_training_dir(directory, batch_size, img_height, img_width, validation_split, seed):\r\n",
    "    training_data = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "        directory = training_dir,\r\n",
    "        validation_split = validation_split,\r\n",
    "        image_size = (img_height, img_width),\r\n",
    "        subset = \"training\",\r\n",
    "        seed = seed,\r\n",
    "        batch_size = batch_size)\r\n",
    "    return training_data\r\n",
    "\r\n",
    "def get_validation_dir(directory, batch_size, img_height, img_width, validation_split, seed):\r\n",
    "    validation_data = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
    "        directory = training_dir,\r\n",
    "        validation_split = validation_split,\r\n",
    "        image_size = (img_height, img_width),\r\n",
    "        batch_size = batch_size,\r\n",
    "        seed = seed,\r\n",
    "        subset = \"validation\")\r\n",
    "    return validation_data \r\n",
    "\r\n",
    "training_data = get_training_dir(training_dir, 64, 180, 180, 0.2, 123)\r\n",
    "validation_data = get_validation_dir(training_dir, 64, 180, 180, 0.2, 123)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 2870 files belonging to 4 classes.\n",
      "Using 2296 files for training.\n",
      "Found 2870 files belonging to 4 classes.\n",
      "Using 574 files for validation.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#Get the class names of the training images\r\n",
    "class_names = training_data.class_names\r\n",
    "print(\"There are:\", len(class_names), \"classes \\nand their names are: \", class_names)\r\n",
    "\r\n",
    "#get the shapes of the images and labels in the training_data\r\n",
    "for images, labels in training_data:\r\n",
    "    print(images.shape)\r\n",
    "    print(labels.shape)\r\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are: 4 classes \n",
      "and their names are:  ['glioma_tumor', 'meningioma_tumor', 'no_tumor', 'pituitary_tumor']\n",
      "(64, 180, 180, 3)\n",
      "(64,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "#prefetch overlaps data preprocessing and model execution while training.\r\n",
    "#cache keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\r\n",
    "\r\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\r\n",
    "training_data = training_data.cache().shuffle(1000).prefetch(buffer_size = AUTOTUNE)\r\n",
    "validation_data = validation_data.cache().prefetch(buffer_size = AUTOTUNE)\r\n",
    "\r\n",
    "normalizing_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\r\n",
    "normalized_ds = training_data.map(lambda x, y: (normalizing_layer(x), y))\r\n",
    "\r\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\r\n",
    "first_image = image_batch[0]\r\n",
    "\r\n",
    "# Notice the pixels values are now in `[0,1]`.\r\n",
    "print(np.min(first_image), np.max(first_image))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.093149036 0.9981472\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "num_classes = len(class_names)\r\n",
    "\r\n",
    "#define data_augmentation\r\n",
    "data_aug = tf.keras.Sequential([\r\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape = (img_height, img_width, 3)),\r\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\r\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1)])\r\n",
    "\r\n",
    "#define a Sequential model\r\n",
    "model = tf.keras.Sequential([\r\n",
    "    data_aug,\r\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\r\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = tf.nn.relu), #if data_augmentation was not used, input_shape would be parameterized here\r\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \r\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = tf.nn.relu),\r\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \r\n",
    "\r\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = tf.nn.relu),\r\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \r\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation = tf.nn.relu),\r\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\r\n",
    "\r\n",
    "    tf.keras.layers.Dropout(0.2),\r\n",
    "    tf.keras.layers.Flatten(),\r\n",
    "    tf.keras.layers.Dense(512, activation = tf.nn.relu),\r\n",
    "    tf.keras.layers.Dense(num_classes, activation = tf.nn.softmax)\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 180, 180, 3)       0         \n",
      "_________________________________________________________________\n",
      "rescaling_2 (Rescaling)      (None, 180, 180, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 178, 178, 64)      1792      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 89, 89, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 87, 87, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 41, 41, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2654720   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 2,769,348\n",
      "Trainable params: 2,769,348\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
    "optimizer = tf.keras.optimizers.Adam(), metrics = ['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "epochs = 10\r\n",
    "history = model.fit(training_data, validation_data = validation_data, epochs = epochs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "36/36 [==============================] - 58s 2s/step - loss: 1.3702 - accuracy: 0.3479 - val_loss: 1.2352 - val_accuracy: 0.5105\n",
      "Epoch 2/10\n",
      "36/36 [==============================] - 61s 2s/step - loss: 1.2705 - accuracy: 0.4642 - val_loss: 1.2165 - val_accuracy: 0.5070\n",
      "Epoch 3/10\n",
      "36/36 [==============================] - 58s 2s/step - loss: 1.2337 - accuracy: 0.4986 - val_loss: 1.2431 - val_accuracy: 0.4669\n",
      "Epoch 4/10\n",
      "36/36 [==============================] - 64s 2s/step - loss: 1.2417 - accuracy: 0.4864 - val_loss: 1.2106 - val_accuracy: 0.5122\n",
      "Epoch 5/10\n",
      "36/36 [==============================] - 58s 2s/step - loss: 1.1861 - accuracy: 0.5434 - val_loss: 1.1844 - val_accuracy: 0.5453\n",
      "Epoch 6/10\n",
      "36/36 [==============================] - 65s 2s/step - loss: 1.1936 - accuracy: 0.5335 - val_loss: 1.1180 - val_accuracy: 0.6254\n",
      "Epoch 7/10\n",
      "36/36 [==============================] - 59s 2s/step - loss: 1.1292 - accuracy: 0.5977 - val_loss: 1.1315 - val_accuracy: 0.6063\n",
      "Epoch 8/10\n",
      "36/36 [==============================] - 58s 2s/step - loss: 1.1115 - accuracy: 0.6238 - val_loss: 1.0680 - val_accuracy: 0.6777\n",
      "Epoch 9/10\n",
      "36/36 [==============================] - 41s 1s/step - loss: 1.0920 - accuracy: 0.6390 - val_loss: 1.0538 - val_accuracy: 0.6847\n",
      "Epoch 10/10\n",
      "36/36 [==============================] - 39s 1s/step - loss: 1.0545 - accuracy: 0.6844 - val_loss: 1.0401 - val_accuracy: 0.6986\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "62777786f8687b9575c0619f17c497edf6c2b58eb2992f0dd825a023781db6e8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}